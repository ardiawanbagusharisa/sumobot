{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dataset_helper import get_dataset_dir, get_dataset, export_dataset\n",
    "\n",
    "# Amount of dataset lines that will be compiled and converted to dataset.jsonl. \n",
    "# If -1, use all lines.\n",
    "# max_dataset=100\n",
    "max_dataset=-1\n",
    "dataset_output_path = f\"{get_dataset_dir()}/classification_dataset.jsonl\"\n",
    "\n",
    "output_onnx_name = \"ml_enhanced_actions.onnx\"\n",
    "output_labels_name = \"ml_enhanced_actions_labels.json\"\n",
    "\n",
    "# Load data\n",
    "# To use existing dataset, use dataset_dir param\n",
    "df, dir = get_dataset()\n",
    "\n",
    "if max_dataset>-1:\n",
    "    df = df.sample(max_dataset)\n",
    "\n",
    "export_dataset(\n",
    "    df,\n",
    "    dataset_output_path,\n",
    "    format=\"jsonl_state_action\",\n",
    "    completion_mode=\"short\",\n",
    "    include_pos_rot=False\n",
    ")\n",
    "\n",
    "print(f\"Saved {len(df)} samples to {dataset_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(f\"Loading data from: {dataset_output_path}\")\n",
    "\n",
    "def parse_state(state_str):\n",
    "    \"\"\"Parse state string to extract features\"\"\"\n",
    "    # Example: \"AngleToEnemy=0.00, AngleToEnemyScore=1.00, DistanceToEnemyScore=0.26, NearBorderArenaScore=0.75, FacingToArena=-1.00.\"\n",
    "    pattern = r\"(\\w+)=([-+]?\\d*\\.?\\d+)\"\n",
    "    matches = re.findall(pattern, state_str)\n",
    "    return {k: float(v) for k, v in matches}\n",
    "\n",
    "def parse_action_enhanced(action_str):\n",
    "    \"\"\"Parse action string to extract skill, dash, movement, and duration\"\"\"\n",
    "    # Example: \"SK, DS, FWD0.11\" or \"TL0.85\" or \"SK\"\n",
    "    # Actions: SK=Skill, DS=Dash, FWD=Forward/Accelerate, TL=TurnLeft, TR=TurnRight\n",
    "    \n",
    "    actions = [a.strip() for a in action_str.split(',')]\n",
    "    \n",
    "    # Check for instant actions\n",
    "    has_skill = 1 if any('SK' in a for a in actions) else 0\n",
    "    has_dash = 1 if any('DS' in a for a in actions) else 0\n",
    "    \n",
    "    # Find movement action with duration\n",
    "    movement = \"None\"  # Default: no movement\n",
    "    duration = 0.0\n",
    "    \n",
    "    for action in actions:\n",
    "        if action.startswith('FWD'):\n",
    "            movement = 'FWD'\n",
    "            duration = float(action[3:]) if len(action) > 3 else 0.0\n",
    "            break\n",
    "        elif action.startswith('TL'):\n",
    "            movement = 'TL'\n",
    "            duration = float(action[2:]) if len(action) > 2 else 0.0\n",
    "            break\n",
    "        elif action.startswith('TR'):\n",
    "            movement = 'TR'\n",
    "            duration = float(action[2:]) if len(action) > 2 else 0.0\n",
    "            break\n",
    "    \n",
    "    return has_skill, has_dash, movement, duration\n",
    "\n",
    "# Load and parse JSONL\n",
    "data = []\n",
    "with open(dataset_output_path, 'r') as f:\n",
    "    for line in f:\n",
    "        if max_dataset > 0 and len(data) >= max_dataset:\n",
    "            break\n",
    "        record = json.loads(line)\n",
    "        state_features = parse_state(record['state'])\n",
    "        has_skill, has_dash, movement, duration = parse_action_enhanced(record['action'])\n",
    "        \n",
    "        data.append({\n",
    "            **state_features,\n",
    "            'has_skill': has_skill,\n",
    "            'has_dash': has_dash,\n",
    "            'movement': movement,\n",
    "            'duration': duration\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "print(f\"\\nSkill distribution:\")\n",
    "print(df['has_skill'].value_counts())\n",
    "print(f\"\\nDash distribution:\")\n",
    "print(df['has_dash'].value_counts())\n",
    "print(f\"\\nMovement distribution:\")\n",
    "print(df['movement'].value_counts())\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tf2onnx\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Features from the parsed state\n",
    "features = [\n",
    "    \"AngleToEnemy\",\n",
    "    \"AngleToEnemyScore\",\n",
    "    \"DistanceToEnemyScore\",\n",
    "    \"NearBorderArenaScore\",\n",
    "    \"FacingToArena\"\n",
    "]\n",
    "\n",
    "X = df[features].values\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Prepare labels for 4 outputs\n",
    "y_skill = df[\"has_skill\"].values.astype(\"float32\")\n",
    "y_dash = df[\"has_dash\"].values.astype(\"float32\")\n",
    "\n",
    "# Encode movement actions\n",
    "le_movement = LabelEncoder()\n",
    "y_movement_encoded = le_movement.fit_transform(df[\"movement\"])\n",
    "y_movement_cat = to_categorical(y_movement_encoded)\n",
    "\n",
    "y_duration = df[\"duration\"].values.astype(\"float32\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_skill_train, y_skill_test, y_dash_train, y_dash_test, y_movement_train, y_movement_test, y_duration_train, y_duration_test = train_test_split(\n",
    "    X, y_skill, y_dash, y_movement_cat, y_duration, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Movement classes: {le_movement.classes_}\")\n",
    "print(f\"Number of movement classes: {y_movement_cat.shape[1]}\")\n",
    "\n",
    "# Build model with 4 outputs\n",
    "inputs = Input(shape=(X.shape[1], ), name=\"input\")\n",
    "\n",
    "# Shared layers\n",
    "# x = Dense(256, activation='relu')(inputs)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dense(32, activation='relu')(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Output 1: Skill (binary)\n",
    "output_skill = Dense(1, activation='sigmoid', name=\"skill\")(x)\n",
    "\n",
    "# Output 2: Dash (binary)\n",
    "output_dash = Dense(1, activation='sigmoid', name=\"dash\")(x)\n",
    "\n",
    "# Output 3: Movement (multi-class)\n",
    "output_movement = Dense(y_movement_cat.shape[1], activation='softmax', name=\"movement\")(x)\n",
    "\n",
    "# Output 4: Duration (regression)\n",
    "output_duration = Dense(1, activation='linear', name=\"duration\")(x)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=inputs, outputs=[output_skill, output_dash, output_movement, output_duration])\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss={\n",
    "        \"skill\": \"binary_crossentropy\",\n",
    "        \"dash\": \"binary_crossentropy\",\n",
    "        \"movement\": CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        \"duration\": \"mae\"\n",
    "    },\n",
    "    metrics={\n",
    "        'skill': 'accuracy',\n",
    "        'dash': 'accuracy',\n",
    "        'movement': 'accuracy',\n",
    "        'duration': 'mae'\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    {\n",
    "        \"skill\": y_skill_train, \n",
    "        \"dash\": y_dash_train,\n",
    "        \"movement\": y_movement_train,\n",
    "        \"duration\": y_duration_train\n",
    "    },\n",
    "    validation_data=(\n",
    "        X_test, \n",
    "        {\n",
    "            'skill': y_skill_test,\n",
    "            'dash': y_dash_test,\n",
    "            'movement': y_movement_test,\n",
    "            'duration': y_duration_test\n",
    "        }\n",
    "    ),\n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stop],\n",
    ")\n",
    "\n",
    "# Predict\n",
    "pred_skill, pred_dash, pred_movement_prob, pred_duration = model.predict(X_test)\n",
    "\n",
    "# Convert predictions\n",
    "pred_skill_binary = (pred_skill > 0.5).astype(int).flatten()\n",
    "pred_dash_binary = (pred_dash > 0.5).astype(int).flatten()\n",
    "pred_movement = np.argmax(pred_movement_prob, axis=1)\n",
    "true_movement = np.argmax(y_movement_test, axis=1)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n=== Skill Classification ===\")\n",
    "print(f\"Accuracy: {(pred_skill_binary == y_skill_test).mean():.4f}\")\n",
    "print(f\"Skill usage - True: {y_skill_test.sum()}, Predicted: {pred_skill_binary.sum()}\")\n",
    "\n",
    "print(\"\\n=== Dash Classification ===\")\n",
    "print(f\"Accuracy: {(pred_dash_binary == y_dash_test).mean():.4f}\")\n",
    "print(f\"Dash usage - True: {y_dash_test.sum()}, Predicted: {pred_dash_binary.sum()}\")\n",
    "\n",
    "print(\"\\n=== Movement Classification Report ===\")\n",
    "print(classification_report(true_movement, pred_movement, target_names=le_movement.classes_))\n",
    "\n",
    "print(f\"\\n=== Duration MAE ===\")\n",
    "print(f\"MAE: {np.mean(np.abs(pred_duration.flatten() - y_duration_test)):.4f}\")\n",
    "\n",
    "# Convert the model to ONNX\n",
    "spec = (tf.TensorSpec((None, X.shape[1]), tf.float32, name=\"input\"),)\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "\n",
    "# Save to file\n",
    "with open(output_onnx_name, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"\\nModel saved to {output_onnx_name}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    \"movement_classes\": le_movement.classes_.tolist(),\n",
    "    \"input_features\": features,\n",
    "    \"outputs\": [\"skill\", \"dash\", \"movement\", \"duration\"]\n",
    "}\n",
    "\n",
    "with open(output_labels_name, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Metadata saved to {output_labels_name}\")\n",
    "print(f\"Movement classes: {metadata['movement_classes']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load ONNX session\n",
    "session = ort.InferenceSession(output_onnx_name)\n",
    "\n",
    "# Load metadata\n",
    "with open(output_labels_name, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "movement_classes = metadata['movement_classes']\n",
    "print(f\"Movement classes: {movement_classes}\")\n",
    "print(f\"Input features: {metadata['input_features']}\")\n",
    "print(f\"Model outputs: {metadata['outputs']}\")\n",
    "\n",
    "# Sample input - features: [AngleToEnemy, AngleToEnemyScore, DistanceToEnemyScore, NearBorderArenaScore, FacingToArena]\n",
    "sample = np.array([[\n",
    "    0.0,    # AngleToEnemy\n",
    "    1.0,    # AngleToEnemyScore (perfect alignment)\n",
    "    0.9,    # DistanceToEnemyScore (very close)\n",
    "    0.5,    # NearBorderArenaScore (mid arena)\n",
    "    -0.5    # FacingToArena (facing inward)\n",
    "]], dtype=np.float32)\n",
    "\n",
    "# Get input & output names\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_names = [o.name for o in session.get_outputs()]\n",
    "\n",
    "print(f\"\\nONNX Input: {input_name}\")\n",
    "print(f\"ONNX Outputs: {output_names}\")\n",
    "\n",
    "# Run inference\n",
    "outputs = session.run(output_names, {input_name: sample})\n",
    "\n",
    "# Unpack outputs (order: skill, dash, movement, duration)\n",
    "pred_skill_prob = outputs[0][0][0]\n",
    "pred_dash_prob = outputs[1][0][0]\n",
    "pred_movement_probs = outputs[2][0]\n",
    "pred_duration = outputs[3][0][0]\n",
    "\n",
    "# Decode predictions\n",
    "use_skill = pred_skill_prob > 0.5\n",
    "use_dash = pred_dash_prob > 0.5\n",
    "movement_index = np.argmax(pred_movement_probs)\n",
    "movement_action = movement_classes[movement_index]\n",
    "\n",
    "print(\"\\n=== Inference Results ===\")\n",
    "print(f\"Skill: {'Yes' if use_skill else 'No'} (confidence: {pred_skill_prob:.4f})\")\n",
    "print(f\"Dash: {'Yes' if use_dash else 'No'} (confidence: {pred_dash_prob:.4f})\")\n",
    "print(f\"Movement: {movement_action}\")\n",
    "print(f\"  Movement probabilities:\")\n",
    "for i, cls in enumerate(movement_classes):\n",
    "    print(f\"    {cls}: {pred_movement_probs[i]:.4f}\")\n",
    "print(f\"Duration: {pred_duration:.4f} seconds\")\n",
    "\n",
    "# Construct final action string\n",
    "final_actions = []\n",
    "if use_skill:\n",
    "    final_actions.append(\"SK\")\n",
    "if use_dash:\n",
    "    final_actions.append(\"DS\")\n",
    "if movement_action != \"None\":\n",
    "    final_actions.append(f\"{movement_action}{pred_duration:.2f}\")\n",
    "\n",
    "final_action_str = \", \".join(final_actions) if final_actions else \"Idle\"\n",
    "print(f\"\\nFinal Action String: {final_action_str}\")\n",
    "\n",
    "# Test with different scenarios\n",
    "print(\"\\n=== Testing Multiple Scenarios ===\")\n",
    "\n",
    "test_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Perfect attack position\",\n",
    "        \"state\": [0.0, 1.0, 0.9, 0.3, -0.8]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Need to turn left\",\n",
    "        \"state\": [45.0, 0.7, 0.5, 0.4, -0.5]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Near border, turn right\",\n",
    "        \"state\": [-30.0, 0.8, 0.6, 0.8, 0.6]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Enemy far away\",\n",
    "        \"state\": [0.0, 1.0, 0.2, 0.3, -0.9]\n",
    "    }\n",
    "]\n",
    "\n",
    "for scenario in test_scenarios:\n",
    "    sample = np.array([scenario[\"state\"]], dtype=np.float32)\n",
    "    outputs = session.run(output_names, {input_name: sample})\n",
    "    \n",
    "    pred_skill_prob = outputs[0][0][0]\n",
    "    pred_dash_prob = outputs[1][0][0]\n",
    "    pred_movement_probs = outputs[2][0]\n",
    "    pred_duration = outputs[3][0][0]\n",
    "    \n",
    "    use_skill = pred_skill_prob > 0.5\n",
    "    use_dash = pred_dash_prob > 0.5\n",
    "    movement_index = np.argmax(pred_movement_probs)\n",
    "    movement_action = movement_classes[movement_index]\n",
    "    \n",
    "    final_actions = []\n",
    "    if use_skill:\n",
    "        final_actions.append(\"SK\")\n",
    "    if use_dash:\n",
    "        final_actions.append(\"DS\")\n",
    "    if movement_action != \"None\":\n",
    "        final_actions.append(f\"{movement_action}{pred_duration:.2f}\")\n",
    "    \n",
    "    final_action_str = \", \".join(final_actions) if final_actions else \"Idle\"\n",
    "    \n",
    "    print(f\"\\n{scenario['name']}:\")\n",
    "    print(f\"  State: {scenario['state']}\")\n",
    "    print(f\"  Action: {final_action_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
